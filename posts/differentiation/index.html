<!DOCTYPE html>
<html lang="en">

<head>
  
  <meta charset="utf-8" />
  <meta content="width=device-width, initial-scale=1" name="viewport" />
  <meta content="#ffffff" name="theme-color" />
  <meta content="#da532c" name="msapplication-TileColor" />

  
<meta property="og:title" content="Animesh Chouhan | How Differentiation Works in Computers?" />
<meta property="og:description" content="" />
<meta property="og:image" content="https://animeshchouhan.com/images/posts/differentiation.jpeg" />
<meta name="description" content="">


  <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.1/css/academicons.min.css" integrity="sha384-FIue+PI4SsI9XfHCz8dBLg33b0c1fMJgNU3X//L26FYbGnlSEfWmNT7zgWc2N9b6" crossorigin="anonymous"> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css"
    integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link href="/deep-thought.css" rel="stylesheet" />
  
  

  
  <link href='&#x2F;icons&#x2F;site.webmanifest' rel="manifest" />
  
  
  <link color="#5bbad5" href='&#x2F;icons&#x2F;safari-pinned-tab.svg' rel="mask-icon" />
  
  
  <link href='&#x2F;icons&#x2F;favicon-16x16.png' rel="icon" sizes="16x16" type="image/png" />
  
  
  <link href='&#x2F;icons&#x2F;favicon-32x32.png' rel="icon" sizes="32x32" type="image/png" />
  
  
  <link href='&#x2F;icons&#x2F;apple-icon.png' rel="apple-touch-icon" sizes="180x180" />
  

  

  

  <title>
    
Animesh Chouhan | How Differentiation Works in Computers?

  </title>

  
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NK695M7L1L"></script>
  <script type="text/javascript">
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());
    gtag("config", "G-NK695M7L1L");
  </script>
  
  

  
  
</head>

<body class="has-background-white">
  <nav aria-label="section navigation" class="navbar is-light" role="navigation">
    <div class="container">
      <div class="navbar-brand">
        <a class="navbar-item is-size-5 has-text-weight-bold" href="/">Animesh Chouhan</a>
        <a aria-expanded="false" aria-label="menu" class="navbar-burger burger" data-target="navMenu" role="button">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu" id="navMenu">
        <div class="navbar-end has-text-centered">
          
          
          
          <a class="navbar-item has-text-weight-semibold" href="&#x2F;">
            Home
          </a>
          
          <a class="navbar-item has-text-weight-semibold" href="&#x2F;projects">
            Projects
          </a>
          
          <a class="navbar-item has-text-weight-semibold" href="&#x2F;posts">
            Posts
          </a>
          
          <a class="navbar-item has-text-weight-semibold" href="&#x2F;vault">
            Vault
          </a>
          
          
          
          <a class="navbar-item has-text-weight-semibold" href="/files/resume-animesh-public.pdf" target="_blank">
            Resume
          </a>
          <!-- <a class="navbar-item" id="nav-search" title="Search" data-target="#search-modal">
            <span class="icon">
              <i class="fas fa-search"></i>
            </span>
          </a> -->
          <a class="navbar-item" id="dark-mode" title="Switch to dark theme">
            <span class="icon">
              <i class="fas fa-adjust"></i>
            </span>
          </a>
        </div>
      </div>
    </div>
  </nav>

  
  

  
<section class="section">
  <div class="container">
    <div class="columns">
      <div class="column is-8 is-offset-2">
        <article class="box">
          <h1 class="title">
            How Differentiation Works in Computers?
          </h1>
          <p class="subtitle"></p>
          <br>
          <div class="columns is-multiline is-gapless">
            <div class="column is-8">
              
<span class="icon-text has-text-grey">
  <!-- <span class="icon">
    <i class="fas fa-user"></i>
  </span> -->
  <!-- <span>Animesh Chouhan published on</span> -->
  <span class="icon">
    <i class="far fa-calendar-alt"></i>
  </span>
  <span><time datetime="2025-06-01">June 01, 2025</time></span>
</span>

            </div>
            <div class="column is-4 has-text-right-desktop">
              
<span class="icon-text has-text-grey">
  <span class="icon">
    <i class="far fa-clock"></i>
  </span>
  <span>21 min,</span>
  <span class="icon">
    <i class="fas fa-pencil-alt"></i>
  </span>
  <span>4126 words</span>
</span>

            </div>
            <div class="column">
              
              
<p>
  Categories:
  
  <a class="has-text-info-dark has-text-weight-semibold"
    href="https://animeshchouhan.com/categories/maths/">
    <span class="icon-text">
      <span class="icon">
        <i class="fas fa-cube"></i>
      </span>
      <span>Maths</span>
    </span>
  </a>
  
  <a class="has-text-info-dark has-text-weight-semibold"
    href="https://animeshchouhan.com/categories/python/">
    <span class="icon-text">
      <span class="icon">
        <i class="fas fa-cube"></i>
      </span>
      <span>Python</span>
    </span>
  </a>
  
  <a class="has-text-info-dark has-text-weight-semibold"
    href="https://animeshchouhan.com/categories/ai/">
    <span class="icon-text">
      <span class="icon">
        <i class="fas fa-cube"></i>
      </span>
      <span>AI</span>
    </span>
  </a>
  
</p>

              
            </div>
            <div class="column has-text-right-desktop">
              
              
<p>
  Tags:
  
  <a class="has-text-info-dark has-text-weight-semibold" href="https://animeshchouhan.com/tags/python/">
    <span class="icon-text">
      <span class="icon">
        <i class="fas fa-tag"></i>
      </span>
      <span>python</span>
    </span>
  </a>
  
  <a class="has-text-info-dark has-text-weight-semibold" href="https://animeshchouhan.com/tags/maths/">
    <span class="icon-text">
      <span class="icon">
        <i class="fas fa-tag"></i>
      </span>
      <span>maths</span>
    </span>
  </a>
  
</p>

              
            </div>
          </div>
          <br>
          <div class="content mt-2">
            <!-- Add summary here -->
<span id="continue-reading"></span><p align="center">
   <img src="/images/posts/differentiation/differentiation.jpeg" alt="differentiation" style="max-width:98%"/>
</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="https://animeshchouhan.com/posts/differentiation/#how-it-started">Introduction</a></li>
<li><a href="https://animeshchouhan.com/posts/differentiation/#differentiation">What is Differentiation?</a></li>
<li><a href="https://animeshchouhan.com/posts/differentiation/#1-symbolic-differentiation">Symbolic Differentiation</a></li>
<li><a href="https://animeshchouhan.com/posts/differentiation/#2-numerical-differentiation">Numerical Differentiation</a></li>
<li><a href="https://animeshchouhan.com/posts/differentiation/#3-automatic-differentiation">Automatic Differentiation</a></li>
<li><a href="https://animeshchouhan.com/posts/differentiation/#wrapping-up">Comparing the Methods</a></li>
<li><a href="https://animeshchouhan.com/posts/differentiation/#references">References</a></li>
</ol>
<h2 id="how-it-started">How It Started?</h2>
<p>It all started when I was watching the YouTube video on <a rel="noopener nofollow noreferrer" target="_blank" href="https://www.youtube.com/watch?v=QwFLA5TrviI&amp;ab_channel=Computerphile">Finding The Slope Algorithm (Forward Mode Automatic Differentiation)</a> by Computerphile:</p>
<p align="center" >
<iframe style="width: 90%;aspect-ratio: 16 / 9;" src="https://www.youtube.com/embed/QwFLA5TrviI?si=Stvftc2CmPGQJGSQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</p>
<p>In this video, Mark Williams demonstrates Forward Mode Automatic Differentiation and explains how it addresses the limitations of traditional methods like <a rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Computer_algebra">Symbolic</a> and <a rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Numerical_differentiation">Numerical</a> Differentiation. The video also introduces the concept of <a rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Dual_number">Dual Numbers</a> and shows how they can be efficiently used to compute the gradient of a function at any point.</p>
<p>Before diving into how computers do it, let‚Äôs quickly revisit what differentiation actually means.</p>
<h2 id="differentiation">Differentiation</h2>
<p>In mathematics, the derivative is a fundamental tool that quantifies the sensitivity to change of a function's output with respect to its input. The derivative of a function of a single variable at a chosen input value, when it exists, is the slope of the tangent line to the graph of the function at that point. The process of finding a <a rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Derivative">derivative</a> is called differentiation.</p>
<p align="center">
   <img src="/images/posts/differentiation/tangent_function_animation.gif" alt="differentiation_animation" style="max-width:98%"/>
</p>
<h3 id="mathematical-definition">Mathematical Definition</h3>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\\(','\\\)']]}});
</script>
<style>
mjx-container{
   overflow-x: auto;
   overflow-y: hidden;
   padding-top: 0.2em;
   /* font-size: 110% !important; */
}
@media (max-width: 768px) {
  pre code {
      font-size: 0.9em
   }
}

</style>
<p>A function of a real variable \( f(x) \) is differentiable at a point \( a \) of its domain, if its domain contains an open interval containing \( ‚Å†a \)‚Å†, and the limit \( L \) exists.</p>
<p>$$
L = \lim_{h \to 0} \frac{f(a + h) - f(a)}{h}
$$</p>
<h2 id="why-we-calculate-derivatives">Why We Calculate Derivatives?</h2>
<p>Derivatives are a fundamental concept in calculus with many practical use cases across science, engineering, economics, and computer science. They measure how a quantity changes in response to a small change in another, commonly called &quot;rate of change&quot;.</p>
<p>Think of a derivatives as answering:</p>
<blockquote>
<p>&quot;If I nudge the input just a little, how much does the output change?&quot;</p>
</blockquote>
<p>This makes derivatives crucial wherever change, sensitivity, or optimization is important. Some important applications include:</p>
<ol>
<li><strong>CFD (Computational Fluid Dynamics)</strong> üåä: Simulates fluid flow by solving Navier‚ÄìStokes equations using partial derivatives of velocity, pressure, and density. These derivatives capture how small changes propagate, enabling realistic real-time simulations of smoke, fire, and airflow.</li>
</ol>
<p align="center">
   <img src="/images/posts/differentiation/cfd.jpg" alt="cfd" style="max-width:70%"/>
</p>
<ol start="2">
<li><strong>Image Processing &amp; Edge Detection</strong> üñºÔ∏è: Image processing uses derivatives like Sobel filters and Laplacians to detect edges by identifying rapid changes in pixel intensity. This helps highlight boundaries for applications in computer vision and object recognition.</li>
</ol>
<p align="center">
   <img src="/images/posts/differentiation/sobel.jpg" alt="sobel" style="max-width:70%"/>
</p>
<ol start="3">
<li><strong>Signal Smoothing &amp; Filtering</strong> üì°: Derivatives detect sudden spikes or noise in audio and sensor data, enabling smoothing and feedback control. This improves performance in applications like music processing, GPS filtering, and motion stabilization.</li>
</ol>
<p align="center">
   <img src="/images/posts/differentiation/signal.png" alt="signal_processing" style="max-width:70%"/>
</p>
<ol start="4">
<li><strong>Machine Learning &amp; AI</strong> üß†: In machine learning, derivatives guide gradient descent by showing how to adjust weights to minimize loss. Backpropagation uses these derivatives to efficiently update neural network parameters during training.</li>
</ol>
<p align="center">
   <img src="/images/posts/differentiation/gradient_descent.jpg" alt="gradient_descent" style="max-width:70%"/>
</p>
<h2 id="differentiation-methods">Differentiation Methods</h2>
<p>When it comes to differentiating with a computer, our first instinct is often the method we learned in high school, using known rules for common functions and applying them step by step. Let‚Äôs take a closer look at how that works!</p>
<h3 id="1-symbolic-differentiation">1. Symbolic Differentiation</h3>
<p>Symbolic differentiation relies on the fundamental definition of a derivative which is taking the limit of the difference quotient. After establishing the derivatives of basic functions, we can systematically apply differentiation rules to compute the derivatives of more complex expressions.</p>
<p>$$
\boxed{L = \lim_{h \to 0} \frac{f(a + h) - f(a)}{h}}
$$</p>
<p>Let‚Äôs calculate it for a simple function: \( f(x)=x^n \)</p>
<p>$$
\displaylines{\begin{align} f(x) &amp;= x^n \\ f'(x) &amp;= \lim_{h \to 0} \frac{f(x+h) - f(x)}{h} \\ &amp;= \lim_{h \to 0} \frac{(x + h)^n - x^n}{h}\end{align}}
$$</p>
<p>Now apply the <strong>Binomial Theorem</strong>:</p>
<p>$$
(x + h)^n = x^n + n x^{n-1} h + \frac{n(n-1)}{2!} x^{n-2} h^2 + \cdots + h^n
$$</p>
<p>Substitute this back into the limit:</p>
<p>$$
\displaylines{\begin{align}f'(x) &amp;= \lim_{h \to 0} \frac{x^n + nx^{n-1}h + \frac{n(n-1)}{2!}x^{n-2}h^2 + \cdots + h^n - x^n}{h} \\ &amp;= \lim_{h \to 0} \frac{nx^{n-1}h + \frac{n(n-1)}{2!}x^{n-2}h^2 + \cdots + h^n}{h} \\ &amp;= \lim_{h \to 0} \left(nx^{n-1} + \frac{n(n-1)}{2!}x^{n-2}h + \cdots + h^{n-1}\right) \\ &amp;= nx^{n-1}\end{align}}
$$</p>
<p>Using the power rule from symbolic differentiation, the derivative is:</p>
<p>$$
\frac{d}{dx} x^n = n x^{n-1}
$$</p>
<p>This rule is one of the foundational results and forms the basis for differentiating more complex expressions built from powers of \(x\). You‚Äôve probably seen a sheet that lists differentiation rules formulas like this:</p>
<p align="center">
   <img src="/images/posts/differentiation/derivative-rules.png" alt="derivate_rules" style="max-width:90%"/>
</p>
<p>By breaking a complex function into smaller components and systematically applying basic rules such as the power, product, and chain rules you can compute the derivative of complex functions step-by-step.</p>
<p>We can implement this in any programming language by defining the fundamental rules and using them to compute derivatives. However, in Python, this functionality is already available through the <code>sympy</code> library. Let‚Äôs look at an example:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">import </span><span style="color:#abb2bf;">sympy </span><span style="color:#cd74e8;">as </span><span style="color:#abb2bf;">sp
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">x </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">sp.</span><span style="color:#eb6772;">Symbol</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;x&quot;</span><span style="color:#abb2bf;">)
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">f </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">x</span><span style="color:#adb7c9;">**</span><span style="color:#db9d63;">2 </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">sp.</span><span style="color:#eb6772;">sin</span><span style="color:#abb2bf;">(x)
</span><span style="color:#abb2bf;">f_prime </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">sp.</span><span style="color:#eb6772;">diff</span><span style="color:#abb2bf;">(f, x)
</span><span style="color:#abb2bf;">
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;f(x):&quot;</span><span style="color:#abb2bf;">, f)
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;f&#39;(x):&quot;</span><span style="color:#abb2bf;">, f_prime)
</span><span style="color:#abb2bf;">
</span><span style="font-style:italic;color:#5f697a;"># Substitute x = œÄ
</span><span style="color:#abb2bf;">value </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">f_prime.</span><span style="color:#eb6772;">subs</span><span style="color:#abb2bf;">(x, sp.pi)
</span><span style="font-style:italic;color:#5f697a;"># Evaluate the numeric value
</span><span style="color:#abb2bf;">numeric_value </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">value.</span><span style="color:#eb6772;">evalf</span><span style="color:#abb2bf;">()
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#cd74e8;">f</span><span style="color:#9acc76;">&quot;f&#39;(œÄ)=</span><span style="color:#abb2bf;">{value}</span><span style="color:#9acc76;">=</span><span style="color:#abb2bf;">{numeric_value}</span><span style="color:#9acc76;">&quot;</span><span style="color:#abb2bf;">)
</span></code></pre>
<p><strong>Output</strong></p>
<pre data-lang="txt" style="background-color:#2b303b;color:#6c7079;" class="language-txt "><code class="language-txt" data-lang="txt"><span style="color:#abb2bf;">f(x): x**2 + sin(x)
</span><span style="color:#abb2bf;">f&#39;(x): 2*x + cos(x)
</span><span style="color:#abb2bf;">f&#39;(œÄ)=-1 + 2*pi=5.28318530717959
</span></code></pre>
<p>While symbolic differentiation provides the exact mathematical expression for a function's rate of change, this elegance often falls short in real-world applications. What if your function isn't a neat equation, but rather a stream of experimental data or a &quot;black-box&quot; algorithm?</p>
<p>In these common scenarios, symbolic methods are simply unfeasible. This is precisely where numerical differentiation comes into picture. By approximating the derivative using discrete function values, it allows us to analyze the behavior of functions derived from empirical observations, complex simulations, or even cutting-edge machine learning models‚Äîareas where symbolic methods can't reach.</p>
<h3 id="2-numerical-differentiation">2. Numerical Differentiation</h3>
<p>Numerical differentiation is the process of approximating the derivative of a function using its values at discrete points, rather than deriving an exact symbolic expression. It's used when a function's formula is unknown, too complex, or only available as data.</p>
<p>The simplest method used for numerical differentiation is finite difference approximations.</p>
<p align="center">
   <img src="/images/posts/differentiation/numerical-diff.png" alt="numerical-differentiation" style="max-width:70%"/>
</p>
<p>A simple two-point estimation is to compute the slope of a nearby secant line through the points \( (x, f(x)) \) and \( (x + h, f(x + h)) \). Choosing a small number \( h \), \( h \) represents a small change in \( x \), and it can be either positive or negative. The slope of this line is</p>
<p>$$
{\displaystyle {\frac {f(x+h)-f(x)}{h}}.}
$$</p>
<p>This expression is <strong>Newton's difference quotient</strong> (also known as a first-order divided difference).</p>
<p>The slope of this secant line differs from the slope of the tangent line by an amount that is approximately proportional to \( h \). As \( h \) approaches zero, the slope of the secant line approaches the slope of the tangent line. Therefore, the true <strong>derivative of f at x</strong> is the limit of the value of the difference quotient as the secant lines get closer and closer to being a tangent line:</p>
<p>$$
{\displaystyle f'(x)=\lim _{h\to 0}{\frac {f(x+h)-f(x)}{h}}.}
$$</p>
<p>We can easily implement numerical differentiation for any function. Let's look at the Python implementation for this:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">import </span><span style="color:#abb2bf;">math
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">f</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">sin</span><span style="color:#abb2bf;">(x)
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">f_dash</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">dx</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">dx) </span><span style="color:#adb7c9;">- </span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x)) </span><span style="color:#adb7c9;">/ </span><span style="color:#abb2bf;">dx
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">x </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">math.pi </span><span style="color:#adb7c9;">/ </span><span style="color:#db9d63;">4
</span><span style="color:#abb2bf;">true_derivative </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">cos</span><span style="color:#abb2bf;">(x)
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;True Derivative: &quot;</span><span style="color:#abb2bf;">, true_derivative)
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;Numerical Derivative: &quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">f_dash</span><span style="color:#abb2bf;">(f, x, </span><span style="color:#eb6772;">dx</span><span style="color:#adb7c9;">=</span><span style="color:#db9d63;">0.0001</span><span style="color:#abb2bf;">))
</span></code></pre>
<p><strong>Output</strong></p>
<pre data-lang="txt" style="background-color:#2b303b;color:#6c7079;" class="language-txt "><code class="language-txt" data-lang="txt"><span style="color:#abb2bf;">True Derivative:  0.7071067811865476
</span><span style="color:#abb2bf;">Numerical Derivative:  0.7070714246693033
</span></code></pre>
</br>
<p>Another two-point formula is to compute the slope of a nearby secant line through the points \( (x ‚àí h, f(x ‚àí h)) \) and \( (x + h, f(x + h)) \). The slope of this line is</p>
<p>$$
{\displaystyle {\frac {f(x+h)-f(x-h)}{2h}}.}
$$</p>
<p>This formula is known as the <strong>Symmetric difference quotient</strong>. In this case the first-order errors cancel, so the slope of these secant lines differ from the slope of the tangent line by an amount that is approximately proportional to \( h^{2} \). Hence for small values of \( h \) this is a more accurate approximation to the tangent line than the one-sided estimation.</p>
<p>Let's implement this in Python:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">import </span><span style="color:#abb2bf;">math
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">f</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">sin</span><span style="color:#abb2bf;">(x)
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">f_dash_symetric</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">dx</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">dx) </span><span style="color:#adb7c9;">- </span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x </span><span style="color:#adb7c9;">- </span><span style="color:#abb2bf;">dx)) </span><span style="color:#adb7c9;">/ </span><span style="color:#abb2bf;">(</span><span style="color:#db9d63;">2 </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">dx)
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">x </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">math.pi </span><span style="color:#adb7c9;">/ </span><span style="color:#db9d63;">4
</span><span style="color:#abb2bf;">true_derivative </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">cos</span><span style="color:#abb2bf;">(x)
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;True Derivative: &quot;</span><span style="color:#abb2bf;">, true_derivative)
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;Numerical Derivative: &quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">f_dash_symetric</span><span style="color:#abb2bf;">(f, x, </span><span style="color:#eb6772;">dx</span><span style="color:#adb7c9;">=</span><span style="color:#db9d63;">0.0001</span><span style="color:#abb2bf;">))
</span></code></pre>
<p><strong>Output</strong></p>
<pre data-lang="txt" style="background-color:#2b303b;color:#6c7079;" class="language-txt "><code class="language-txt" data-lang="txt"><span style="color:#abb2bf;">True Derivative:  0.7071067811865476
</span><span style="color:#abb2bf;">Numerical Derivative:  0.70710678000796
</span></code></pre>
</br>
<p>Numerical differentiation is quick and easy to implement, especially when an explicit formula for the derivative is unavailable or the function is defined only through data points.</p>
<p>However, it comes with certain limitations. The results are highly sensitive to the choice of step size, too large and the approximation is inaccurate; too small and rounding errors dominate due to floating-point precision limits. The following diagram represents this tradeoff and the sweet-spot for accurate calculations.</p>
<p align="center">
   <img src="/images/posts/differentiation/AbsoluteErrorNumericalDifferentiationExample.png" alt="AbsoluteErrorNumericalDifferentiation" style="max-width:90%"/>
</p>
<p>Let's try to replicate the results by calculating this error and plotting using Matplotlib:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">import </span><span style="color:#abb2bf;">math
</span><span style="color:#cd74e8;">import </span><span style="color:#abb2bf;">matplotlib.pyplot </span><span style="color:#cd74e8;">as </span><span style="color:#abb2bf;">plt
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">f</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">sin</span><span style="color:#abb2bf;">(x)
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">f_dash</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">dx</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="font-style:italic;color:#5f697a;"># Newton&#39;s difference
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">dx) </span><span style="color:#adb7c9;">- </span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x)) </span><span style="color:#adb7c9;">/ </span><span style="color:#abb2bf;">dx
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">f_dash_symetric</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">dx</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="font-style:italic;color:#5f697a;"># Symmetric difference
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">dx) </span><span style="color:#adb7c9;">- </span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x </span><span style="color:#adb7c9;">- </span><span style="color:#abb2bf;">dx)) </span><span style="color:#adb7c9;">/ </span><span style="color:#abb2bf;">(</span><span style="color:#db9d63;">2 </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">dx)
</span><span style="color:#abb2bf;">
</span><span style="font-style:italic;color:#5f697a;"># Point at which to differentiate
</span><span style="color:#abb2bf;">x </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">math.pi </span><span style="color:#adb7c9;">/ </span><span style="color:#db9d63;">4
</span><span style="color:#abb2bf;">true_derivative </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">cos</span><span style="color:#abb2bf;">(x)
</span><span style="color:#abb2bf;">
</span><span style="font-style:italic;color:#5f697a;"># dx values
</span><span style="color:#abb2bf;">dx_values </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">[</span><span style="color:#db9d63;">2 </span><span style="color:#adb7c9;">** </span><span style="color:#abb2bf;">(</span><span style="color:#adb7c9;">-</span><span style="color:#abb2bf;">i) </span><span style="color:#cd74e8;">for </span><span style="color:#abb2bf;">i </span><span style="color:#cd74e8;">in </span><span style="color:#5ebfcc;">range</span><span style="color:#abb2bf;">(</span><span style="color:#db9d63;">1</span><span style="color:#abb2bf;">, </span><span style="color:#db9d63;">50</span><span style="color:#abb2bf;">)]
</span><span style="color:#abb2bf;">
</span><span style="font-style:italic;color:#5f697a;"># Compute numerical derivatives and errors
</span><span style="color:#abb2bf;">errors_newton </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">[</span><span style="color:#5ebfcc;">abs</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f_dash</span><span style="color:#abb2bf;">(f, x, dx) </span><span style="color:#adb7c9;">- </span><span style="color:#abb2bf;">true_derivative) </span><span style="color:#cd74e8;">for </span><span style="color:#abb2bf;">dx </span><span style="color:#cd74e8;">in </span><span style="color:#abb2bf;">dx_values]
</span><span style="color:#abb2bf;">errors_symmetric </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">[
</span><span style="color:#abb2bf;">    </span><span style="color:#5ebfcc;">abs</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f_dash_symetric</span><span style="color:#abb2bf;">(f, x, dx) </span><span style="color:#adb7c9;">- </span><span style="color:#abb2bf;">true_derivative) </span><span style="color:#cd74e8;">for </span><span style="color:#abb2bf;">dx </span><span style="color:#cd74e8;">in </span><span style="color:#abb2bf;">dx_values
</span><span style="color:#abb2bf;">]
</span><span style="color:#abb2bf;">
</span><span style="font-style:italic;color:#5f697a;"># Plotting
</span><span style="color:#abb2bf;">plt.</span><span style="color:#eb6772;">figure</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">figsize</span><span style="color:#adb7c9;">=</span><span style="color:#abb2bf;">(</span><span style="color:#db9d63;">16</span><span style="color:#abb2bf;">, </span><span style="color:#db9d63;">9</span><span style="color:#abb2bf;">))
</span><span style="color:#abb2bf;">plt.</span><span style="color:#eb6772;">loglog</span><span style="color:#abb2bf;">(dx_values, errors_newton, </span><span style="color:#eb6772;">marker</span><span style="color:#adb7c9;">=</span><span style="color:#9acc76;">&quot;o&quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">label</span><span style="color:#adb7c9;">=</span><span style="color:#9acc76;">&quot;Newton&#39;s Difference&quot;</span><span style="color:#abb2bf;">)
</span><span style="color:#abb2bf;">plt.</span><span style="color:#eb6772;">loglog</span><span style="color:#abb2bf;">(dx_values, errors_symmetric, </span><span style="color:#eb6772;">marker</span><span style="color:#adb7c9;">=</span><span style="color:#9acc76;">&quot;s&quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">label</span><span style="color:#adb7c9;">=</span><span style="color:#9acc76;">&quot;Symmetric Difference&quot;</span><span style="color:#abb2bf;">)
</span><span style="color:#abb2bf;">plt.</span><span style="color:#eb6772;">xlabel</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;dx (step size)&quot;</span><span style="color:#abb2bf;">)
</span><span style="color:#abb2bf;">plt.</span><span style="color:#eb6772;">ylabel</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;Absolute Error&quot;</span><span style="color:#abb2bf;">)
</span><span style="color:#abb2bf;">plt.</span><span style="color:#eb6772;">title</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;Error Comparison of Numerical Differentiation Methods at x = œÄ/4&quot;</span><span style="color:#abb2bf;">)
</span><span style="color:#abb2bf;">plt.</span><span style="color:#eb6772;">grid</span><span style="color:#abb2bf;">(</span><span style="color:#db9d63;">True</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">which</span><span style="color:#adb7c9;">=</span><span style="color:#9acc76;">&quot;both&quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">ls</span><span style="color:#adb7c9;">=</span><span style="color:#9acc76;">&quot;--&quot;</span><span style="color:#abb2bf;">)
</span><span style="color:#abb2bf;">plt.</span><span style="color:#eb6772;">legend</span><span style="color:#abb2bf;">()
</span><span style="color:#abb2bf;">plt.</span><span style="color:#eb6772;">show</span><span style="color:#abb2bf;">()
</span></code></pre>
<p><strong>Output:</strong></p>
<p align="center">
   <img src="/images/posts/differentiation/numerical-diff-comparison.png" alt="Numerical Differentiation Comparison" style="max-width:95%"/>
</p>
<p>We observe a similar pattern as in the previous diagram, highlighting how numerical differentiation is sensitive to step size. Apart from this it also tends to amplify any noise in the data, making it unreliable for real-world measurements or simulations with fluctuations. Additionally, it provides only pointwise estimates and does not yield a general formula, limiting its usefulness in analytical studies or symbolic manipulation.</p>
<h3 id="3-automatic-differentiation">3. Automatic Differentiation</h3>
<p>Now let‚Äôs look into automatic differentiation, a powerful technique that computes exact derivatives by breaking down functions into elementary operations and applying the chain rule systematically.</p>
<p>Unlike numerical differentiation, it avoids rounding and truncation errors, and unlike symbolic differentiation, it scales well with complex functions. Both of these classical methods have problems with calculating higher derivatives, where complexity and errors increase. This makes automatic differentiation especially powerful in machine learning and scientific computing where accurate gradients are essential.</p>
<p align="center">
   <img src="/images/posts/differentiation/ForwardAccumulationAutomaticDifferentiation.png" alt="Automatic Differentiation" style="max-width:90%"/>
</p>
<p>Auto-differentiation is thus neither numeric nor symbolic, nor is it a combination of both. It is also preferable to ordinary numerical methods: In contrast to the more traditional numerical methods based on finite differences, auto-differentiation is 'in theory' exact, and in comparison to symbolic algorithms, it is computationally inexpensive.</p>
<p>Automatic Differentiation (AD) is a structured, algorithmic method for efficiently computing derivatives by systematically applying the chain rule. At its core, AD relies on breaking down the differentiation process using the chain rule for composite functions.</p>
<p>For a nested function:</p>
<p>$$
y = f(g(h(x))) = f(g(h(w_0))) = f(g(w_1)) = f(w_2) = w_3
$$</p>
<p>with intermediate variables:</p>
<p>$$
\displaylines{\begin{align}w_0 &amp;= x \\ \quad w_1 &amp;= h(w_0) \\ \quad w_2 &amp;= g(w_1) \\ \quad w_3 &amp;= f(w_2) = y\end{align}}
$$</p>
<p>the chain rule gives:</p>
<p>$$
\frac{\partial y}{\partial x} = \frac{\partial y}{\partial w_2} \cdot \frac{\partial w_2}{\partial w_1} \cdot \frac{\partial w_1}{\partial x} = \frac{\partial f(w_2)}{\partial w_2} \cdot \frac{\partial g(w_1)}{\partial w_1} \cdot \frac{\partial h(w_0)}{\partial x}.
$$</p>
<h4 id="types-of-automatic-differentiation">Types of Automatic Differentiation</h4>
<p>Usually, two distinct modes of automatic differentiation are presented:</p>
<ul>
<li>Forward accumulation (also called bottom-up, forward mode, or tangent mode)</li>
<li>Reverse accumulation (also called top-down, reverse mode, or adjoint mode)</li>
</ul>
<p>Forward accumulation specifies that one traverses the chain rule from inside to outside (that is, first compute \( \partial w_{1}/\partial x \) and then \( \partial w_{2}/\partial w_{1} \) and lastly \( \partial y/\partial w*{2}\) ), while reverse accumulation traverses from outside to inside (first compute \( \partial y/\partial w_{2} \) and then \( \partial w_{2}/\partial w_{1} \) and lastly \( \partial w_{1}/\partial x\) ).</p>
<h4 id="forward-mode-automatic-differentiation">Forward-mode Automatic Differentiation</h4>
<p>In forward accumulation AD, one first fixes the independent variable with respect to which differentiation is performed and computes the derivative of each sub-expression recursively. In a pen-and-paper calculation, this involves repeatedly substituting the derivative of the inner functions in the chain rule:</p>
<p>Let the chain of intermediate variables be:</p>
<p>$$
w_0 = x, \quad w_1 = f_1(w_0), \quad w_2 = f_2(w_1), \quad \dots, \quad w_n = f_n(w_{n-1}) = y
$$</p>
<p>Then, by the chain rule, the derivative of \( y \) with respect to \( x \) is:</p>
<p>$$
\frac{dy}{dx} = \frac{dw_n}{dw_{n-1}} \cdot \frac{dw_{n-1}}{dw_{n-2}} \cdot \dots \cdot \frac{dw_1}{dw_0}
$$</p>
<p>In forward mode automatic differentiation, we compute both the value and the derivative of each intermediate variable \( w_i \) in a single forward pass:</p>
<p>$$
\text{For each } i = 1 \text{ to } n: \displaylines{\begin{align} w_i &amp;= f_i(w_{i-1}) \\ \dot{w_i} &amp;= f_i'(w_{i-1}) \cdot \dot{w}_{i-1} \end{align}}
$$</p>
<p>where \( \dot{w}_i = \frac{dw_i}{dx} \) denotes the derivative of \( w_i \) with respect to the fixed input variable \( x \).</p>
<p align="center">
   <img src="/images/posts/differentiation/ForwardAD.png" alt="Forward Automatic Differentiation" style="max-width:90%"/>
</p>
<p>We will now look at the dual number-based implementation of forward mode automatic differentiation, which allows us to compute derivatives alongside function evaluations in a natural and efficient way.</p>
<h4 id="dual-numbers">Dual Numbers</h4>
<p><strong>Definition</strong></p>
<p>Dual numbers extend the real numbers by introducing a new element \( \varepsilon \) (epsilon) such that:</p>
<p>$$
\varepsilon^2 = 0, \quad \varepsilon \ne 0
$$</p>
<p>Any dual number has the form:</p>
<p>$$
a + b\varepsilon
$$</p>
<p>where:</p>
<ul>
<li>\( a \) and \( b \) are real numbers,</li>
<li>\( \varepsilon \) is a \( \textit{nilpotent} \) element (i.e., its square is zero).</li>
</ul>
<p><strong>Arithmetic</strong></p>
<p>Let \( x = a + b\varepsilon \), \( y = c + d\varepsilon \).</p>
<ol>
<li>
<p><strong>Addition:</strong></p>
<p>$$
x + y = (a + c) + (b + d)\varepsilon
$$</p>
</li>
<li>
<p><strong>Multiplication:</strong></p>
<p>$$
x \cdot y = (a + b\varepsilon) * (c + d\varepsilon) = ac + (ad + bc)\varepsilon \quad \text{(since } \varepsilon^2 = 0 \text{)}
$$</p>
</li>
</ol>
<p><strong>Automatic Differentiation</strong></p>
<p>Consider the Taylor series expansion of a function \( f(x) \) evaluated at the point \( x+\varepsilon \):</p>
<p>$$
f(x+\varepsilon) = f(x) + f'(x)\varepsilon + \frac{1}{2}f''(x)\varepsilon^2 + \cdots
$$</p>
<p>Due to the property of dual numbers where \( \varepsilon^2 = 0 \), therefore \( \varepsilon_1^k = 0 \) for all \( k &gt; 1 \), all higher-order terms in the expansion vanish. Consequently, the Taylor series reduces to:</p>
<p>$$
f(x+\varepsilon) = f(x) + \varepsilon f'(x)
$$</p>
<p>This truncation occurs because the dual number property eliminates all polynomial terms of degree two and higher, leaving only the linear approximation. Therefore, if you evaluate a function \( f(a + b\varepsilon) \), you get:</p>
<p>$$
f(a + b\varepsilon) = f(a) + b f'(a)\varepsilon
$$</p>
<p>This means you can compute both \( f(a) \) and \( f'(a) \) in one pass, a powerful technique in machine learning and scientific computing. Let's implement the dual numbers in Python:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">import </span><span style="color:#abb2bf;">math
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">class </span><span style="color:#f0c678;">Dual</span><span style="color:#adb7c9;">:
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">def </span><span style="color:#5ebfcc;">__init__</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">real</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">dual</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">        </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">real
</span><span style="color:#abb2bf;">        </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">dual
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">def </span><span style="color:#5ebfcc;">__str__</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">return f</span><span style="color:#9acc76;">&quot;</span><span style="color:#abb2bf;">{</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real}</span><span style="color:#9acc76;">+</span><span style="color:#abb2bf;">{</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual}</span><span style="color:#9acc76;">Œµ&quot;
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">def </span><span style="color:#5ebfcc;">__add__</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">other</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">if </span><span style="color:#5ebfcc;">isinstance</span><span style="color:#abb2bf;">(other, Dual):
</span><span style="color:#abb2bf;">            real </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">other.real
</span><span style="color:#abb2bf;">            dual </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">other.dual
</span><span style="color:#abb2bf;">            </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(real, dual)
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">other, </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual)
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#5ebfcc;">__radd__ </span><span style="color:#adb7c9;">= </span><span style="color:#5ebfcc;">__add__
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">def </span><span style="color:#5ebfcc;">__mul__</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">other</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">if </span><span style="color:#5ebfcc;">isinstance</span><span style="color:#abb2bf;">(other, Dual):
</span><span style="color:#abb2bf;">            real </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other.real
</span><span style="color:#abb2bf;">            dual </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other.dual </span><span style="color:#adb7c9;">+ </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other.real
</span><span style="color:#abb2bf;">            </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(real, dual)
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other, </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other)
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#5ebfcc;">__rmul__ </span><span style="color:#adb7c9;">= </span><span style="color:#5ebfcc;">__mul__
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">d1 </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(</span><span style="color:#db9d63;">3</span><span style="color:#abb2bf;">, </span><span style="color:#db9d63;">2</span><span style="color:#abb2bf;">)
</span><span style="color:#abb2bf;">d2 </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(</span><span style="color:#db9d63;">4</span><span style="color:#abb2bf;">, </span><span style="color:#db9d63;">5</span><span style="color:#abb2bf;">)
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#cd74e8;">f</span><span style="color:#9acc76;">&quot;d1: </span><span style="color:#abb2bf;">{d1}</span><span style="color:#9acc76;">, d2: </span><span style="color:#abb2bf;">{d2}</span><span style="color:#9acc76;">&quot;</span><span style="color:#abb2bf;">)
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;d1+d2 =&quot;</span><span style="color:#abb2bf;">, d1 </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">d2)
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;d1*d2 =&quot;</span><span style="color:#abb2bf;">, d1 </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">d2)
</span></code></pre>
<p><strong>Output</strong></p>
<pre data-lang="txt" style="background-color:#2b303b;color:#6c7079;" class="language-txt "><code class="language-txt" data-lang="txt"><span style="color:#abb2bf;">d1: 3+2Œµ, d2: 4+5Œµ
</span><span style="color:#abb2bf;">d1+d2 = 7+7Œµ
</span><span style="color:#abb2bf;">d1*d2 = 12+23Œµ
</span></code></pre>
</br>
<p>Before we move on to the implementation of differentiation using dual numbers, which is quite easy, we need to first implement another commonly used function: the power function.</p>
<p>Let \( x=a+bŒµ \), and suppose you want to compute \( x^y \), considering two cases:</p>
<p><strong>Case 1:</strong> \( y \in \mathbb{R} \) (a real exponent)</p>
<p>Let \( y = n \in \mathbb{R} \). Using the first-order Taylor expansion:</p>
<p>$$
x^n = (a + b\varepsilon)^n = a^n + n a^{n-1} b \varepsilon
$$</p>
<p>Thus, the result is:</p>
<ul>
<li>Real part: \( a^n \)</li>
<li>Dual part: \( n a^{n-1} b \)</li>
</ul>
<p>Which gives:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#abb2bf;">real </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real</span><span style="color:#adb7c9;">**</span><span style="color:#abb2bf;">other
</span><span style="color:#abb2bf;">dual </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">other </span><span style="color:#adb7c9;">* </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">** </span><span style="color:#abb2bf;">(other </span><span style="color:#adb7c9;">- </span><span style="color:#db9d63;">1</span><span style="color:#abb2bf;">) </span><span style="color:#adb7c9;">* </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual
</span></code></pre>
<p><strong>Case 2:</strong> \( y = c + d\varepsilon \) (a dual exponent)</p>
<p>We use the identity:</p>
<p>$$
x^y = e^{y \cdot \ln x}
$$</p>
<p>First compute:</p>
<p>$$
\ln x = \ln(a + b\varepsilon) = \ln a + \frac{b}{a} \varepsilon
$$</p>
<p>Then:</p>
<p>$$
y \cdot \ln x = (c + d\varepsilon)(\ln a + \frac{b}{a} \varepsilon)
= c \ln a + \left( d \ln a + \frac{c b}{a} \right) \varepsilon
$$</p>
<p>Now exponentiate:</p>
<p>$$
e^{c \ln a + \left( d \ln a + \frac{c b}{a} \right) \varepsilon}
= a^c + a^c \left( d \ln a + \frac{c b}{a} \right) \varepsilon
$$</p>
<p>So:</p>
<ul>
<li>Real part: \( a^c \)</li>
<li>Dual part: \( a^c \left( \frac{c b}{a} + d \ln a \right) \)</li>
</ul>
<p>This gives:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#abb2bf;">real </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">** </span><span style="color:#abb2bf;">other.real
</span><span style="color:#abb2bf;">dual </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">real </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">(
</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other.real </span><span style="color:#adb7c9;">/ </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real) </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">other.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">log</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real)
</span><span style="color:#abb2bf;">)
</span></code></pre>
<p>Now to calculate the derivative of a function, evaluating a function \( f \) at the dual number \( x + \varepsilon \), we get:</p>
<p>$$
f(x + \varepsilon) = f(x) + f'(x)\varepsilon
$$</p>
<p>The real part is the value of the function, and the dual part gives the derivative. Hence, we can extract the derivative directly from the dual component. The derivative of \( f \) at a point \( x \) can be computed using:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">diff</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(x, </span><span style="color:#db9d63;">1</span><span style="color:#abb2bf;">)).dual
</span></code></pre>
<p>Here, we construct the dual number \( x + 1 \cdot \varepsilon \). When \( f \) is evaluated on this dual number, it propagates the derivative information through all operations. The final <code>.dual</code> part gives us \( f'(x) \).</p>
<p>Now putting everything together we have:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">import </span><span style="color:#abb2bf;">math
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">class </span><span style="color:#f0c678;">Dual</span><span style="color:#adb7c9;">:
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">def </span><span style="color:#5ebfcc;">__init__</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">real</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">dual</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">        </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">real
</span><span style="color:#abb2bf;">        </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">dual
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">def </span><span style="color:#5ebfcc;">__str__</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">return f</span><span style="color:#9acc76;">&quot;</span><span style="color:#abb2bf;">{</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real}</span><span style="color:#9acc76;">+</span><span style="color:#abb2bf;">{</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual}</span><span style="color:#9acc76;">Œµ&quot;
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">def </span><span style="color:#5ebfcc;">__add__</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">other</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">if </span><span style="color:#5ebfcc;">isinstance</span><span style="color:#abb2bf;">(other, Dual):
</span><span style="color:#abb2bf;">            real </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">other.real
</span><span style="color:#abb2bf;">            dual </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">other.dual
</span><span style="color:#abb2bf;">            </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(real, dual)
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">other, </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual)
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#5ebfcc;">__radd__ </span><span style="color:#adb7c9;">= </span><span style="color:#5ebfcc;">__add__
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">def </span><span style="color:#5ebfcc;">__mul__</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">other</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">if </span><span style="color:#5ebfcc;">isinstance</span><span style="color:#abb2bf;">(other, Dual):
</span><span style="color:#abb2bf;">            real </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other.real
</span><span style="color:#abb2bf;">            dual </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other.dual </span><span style="color:#adb7c9;">+ </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other.real
</span><span style="color:#abb2bf;">            </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(real, dual)
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other, </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other)
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#5ebfcc;">__rmul__ </span><span style="color:#adb7c9;">= </span><span style="color:#5ebfcc;">__mul__
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">def </span><span style="color:#5ebfcc;">__pow__</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">other</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">if </span><span style="color:#5ebfcc;">isinstance</span><span style="color:#abb2bf;">(other, (int, float)):
</span><span style="color:#abb2bf;">            real </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real</span><span style="color:#adb7c9;">**</span><span style="color:#abb2bf;">other
</span><span style="color:#abb2bf;">            dual </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">other </span><span style="color:#adb7c9;">* </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real </span><span style="color:#adb7c9;">** </span><span style="color:#abb2bf;">(other </span><span style="color:#adb7c9;">- </span><span style="color:#db9d63;">1</span><span style="color:#abb2bf;">) </span><span style="color:#adb7c9;">* </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual
</span><span style="color:#abb2bf;">            </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(real, dual)
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">elif </span><span style="color:#5ebfcc;">isinstance</span><span style="color:#abb2bf;">(other, Dual):
</span><span style="color:#abb2bf;">            real </span><span style="color:#adb7c9;">= </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real</span><span style="color:#adb7c9;">**</span><span style="color:#abb2bf;">other.real
</span><span style="color:#abb2bf;">            dual </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">real </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">(
</span><span style="color:#abb2bf;">                (</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">other.real </span><span style="color:#adb7c9;">/ </span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real) </span><span style="color:#adb7c9;">+ </span><span style="color:#abb2bf;">other.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">log</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">self</span><span style="color:#abb2bf;">.real)
</span><span style="color:#abb2bf;">            )
</span><span style="color:#abb2bf;">            </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(real, dual)
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">else</span><span style="color:#abb2bf;">:
</span><span style="color:#abb2bf;">            </span><span style="color:#cd74e8;">return </span><span style="color:#db9d63;">NotImplemented
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">
</span><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">diff</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(x, </span><span style="color:#db9d63;">1</span><span style="color:#abb2bf;">)).dual
</span></code></pre>
<p>Let's try to find the derivative of a polynomial function using our implementation.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">f</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">x</span><span style="color:#adb7c9;">**</span><span style="color:#db9d63;">2 </span><span style="color:#adb7c9;">+ </span><span style="color:#db9d63;">3 </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">x </span><span style="color:#adb7c9;">+ </span><span style="color:#db9d63;">2
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">x </span><span style="color:#adb7c9;">= </span><span style="color:#db9d63;">5
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;f(x) = &quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x))
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;f&#39;(x) = &quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">diff</span><span style="color:#abb2bf;">(f, x))
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;f&#39;(x) = &quot;</span><span style="color:#abb2bf;">, </span><span style="color:#db9d63;">2 </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">x </span><span style="color:#adb7c9;">+ </span><span style="color:#db9d63;">3</span><span style="color:#abb2bf;">)
</span></code></pre>
<p><strong>Output</strong></p>
<pre data-lang="txt" style="background-color:#2b303b;color:#6c7079;" class="language-txt "><code class="language-txt" data-lang="txt"><span style="color:#abb2bf;">f(x) =  42
</span><span style="color:#abb2bf;">f&#39;(x) =  13
</span><span style="color:#abb2bf;">f&#39;(x) =  13
</span></code></pre>
</br>
<p>We can use similar approach to calculate the propagation of derivatives for trigonometric function like \( \sin(x) \) and \( \cos(x) \), where \( x \in \mathbb{D} \) (dual numbers). We use Taylor expansion and the chain rule to propagate derivatives through the dual part.</p>
<p><strong>Sine Function</strong></p>
<p>$$
\sin(x) = \sin(a + b\varepsilon)
$$</p>
<p>Using first-order Taylor expansion:</p>
<p>$$
\sin(a + b\varepsilon) = \sin(a) + b\varepsilon \cdot \cos(a)
$$</p>
<p>So, the result is:</p>
<p>$$
\text{real part: } \sin(a), \quad \text{dual part: } b \cos(a)
$$</p>
<p>In code:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">sin</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">if </span><span style="color:#5ebfcc;">isinstance</span><span style="color:#abb2bf;">(x, Dual):
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(math.</span><span style="color:#eb6772;">sin</span><span style="color:#abb2bf;">(x.real), x.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">cos</span><span style="color:#abb2bf;">(x.real))
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">sin</span><span style="color:#abb2bf;">(x)
</span></code></pre>
<p><strong>Cosine Function</strong></p>
<p>$$
\cos(x) = \cos(a + b\varepsilon)
$$</p>
<p>Using Taylor expansion:</p>
<p>$$
\cos(a + b\varepsilon) = \cos(a) - b\varepsilon \cdot \sin(a)
$$</p>
<p>So, the result is:</p>
<p>$$
\text{real part: } \cos(a), \quad \text{dual part: } -b \sin(a)
$$</p>
<p>In code:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">cos</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">if </span><span style="color:#5ebfcc;">isinstance</span><span style="color:#abb2bf;">(x, Dual):
</span><span style="color:#abb2bf;">        </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">Dual</span><span style="color:#abb2bf;">(math.</span><span style="color:#eb6772;">cos</span><span style="color:#abb2bf;">(x.real), </span><span style="color:#adb7c9;">-</span><span style="color:#abb2bf;">x.dual </span><span style="color:#adb7c9;">* </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">sin</span><span style="color:#abb2bf;">(x.real))
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#abb2bf;">math.</span><span style="color:#eb6772;">cos</span><span style="color:#abb2bf;">(x)
</span></code></pre>
<p>Let's test our implementation:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#6c7079;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#cd74e8;">def </span><span style="color:#5cb3fa;">f</span><span style="color:#abb2bf;">(</span><span style="color:#eb6772;">x</span><span style="color:#abb2bf;">):
</span><span style="color:#abb2bf;">    </span><span style="color:#cd74e8;">return </span><span style="color:#eb6772;">sin</span><span style="color:#abb2bf;">(x)
</span><span style="color:#abb2bf;">
</span><span style="color:#abb2bf;">x </span><span style="color:#adb7c9;">= </span><span style="color:#abb2bf;">math.pi </span><span style="color:#adb7c9;">/ </span><span style="color:#db9d63;">3
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;f(x) = &quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">f</span><span style="color:#abb2bf;">(x))
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;f&#39;(x) = &quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">diff</span><span style="color:#abb2bf;">(f, x))
</span><span style="color:#5ebfcc;">print</span><span style="color:#abb2bf;">(</span><span style="color:#9acc76;">&quot;f&#39;(x) = cos(x) = &quot;</span><span style="color:#abb2bf;">, </span><span style="color:#eb6772;">cos</span><span style="color:#abb2bf;">(x))
</span></code></pre>
<p><strong>Output</strong></p>
<pre data-lang="txt" style="background-color:#2b303b;color:#6c7079;" class="language-txt "><code class="language-txt" data-lang="txt"><span style="color:#abb2bf;">f(x) =  0.8660254037844386
</span><span style="color:#abb2bf;">f&#39;(x) =  0.5000000000000001
</span><span style="color:#abb2bf;">f&#39;(x) = cos(x) =  0.5000000000000001
</span></code></pre>
</br>
<p>In summary, forward-mode automatic differentiation leverages dual numbers to elegantly propagate derivatives alongside values. By evaluating functions on dual inputs, we can compute exact derivatives with minimal changes to the original code, making this technique both efficient and easy to implement.</p>
<h4 id="reverse-mode-automatic-differentiation">Reverse-mode Automatic Differentiation</h4>
<p>It's worth noting that another powerful technique exists: reverse-mode automatic differentiation, which is more efficient when computing gradients of functions with many inputs and a single output‚Äîlike in deep learning. However, reverse mode requires building a computational graph and performing a backward pass, which adds complexity. We won‚Äôt cover reverse-mode here, as that would make this post significantly longer.</p>
<p align="center">
   <img src="/images/posts/differentiation/ReverseaccumulationAD.png" alt="Reverse Automatic Differentiation" style="max-width:90%"/>
</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>Differentiation is at the heart of optimization, and in today's machine learning and scientific computing workflows, automatic differentiation offers the best of both worlds: precision and efficiency.</p>
<p>We‚Äôve seen how to go from symbolic and numerical methods to a more scalable and elegant solution, one that can be embedded directly in code with minimal overhead. Forward-mode using dual numbers provides an elegant way to compute derivatives by augmenting the real number system and propagating derivatives alongside values.</p>
<p>Different differentiation methods serve different needs depending on the context. Here‚Äôs a quick comparison of symbolic, numerical, and automatic differentiation to help you understand when to use which:</p>
<table><thead><tr><th>Method</th><th>Pros</th><th>Cons</th><th>Best for</th></tr></thead><tbody>
<tr><td>Symbolic</td><td>Exact derivatives</td><td>Slow for complex functions</td><td>Math-heavy functions</td></tr>
<tr><td>Numerical</td><td>Simple to implement</td><td>Inaccurate, error-prone</td><td>Unknown/black-box functions</td></tr>
<tr><td>Automatic</td><td>Accurate and efficient</td><td>Harder to implement manually</td><td>ML, optimization problems</td></tr>
</tbody></table>
<p>If you‚Äôve come this far, thank you! I hope this post demystified how computers differentiate functions and how that knowledge translates into real-world applications.</p>
<p>Until next time, keep exploring, and keep differentiating üßÆüöÄ</p>
<h2 id="references">References</h2>
<ol>
<li><a rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Derivative">Derivative - Wikipedia</a></li>
<li><a rel="noopener nofollow noreferrer" target="_blank" href="https://www.mathmindsacademy.com/differentiation-rules.html">Differentiation Rules</a></li>
<li><a rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Numerical_differentiation">Numerical differentiation - Wikipedia</a></li>
<li><a rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Automatic_differentiation">Automatic differentiation - Wikipedia</a></li>
<li><a rel="noopener nofollow noreferrer" target="_blank" href="https://arxiv.org/html/2501.04159v1">Dual Numbers for Arbitrary Order Automatic Differentiation</a></li>
</ol>
<h2 id="stay-tuned">Stay Tuned</h2>
<p>Hope you enjoyed reading this. Stay tuned for more cool stuff coming your way!<br><br></p>
<p align="center">
<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/4JGKZS7h4Qa16gOU3oNETV?utm_source=generator" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
</p>

          </div>
        </article>
      </div>
      
    </div>
  </div>
</section>


  
  <section class="modal" id="search-modal">
    <div class="modal-background"></div>
    <div class="modal-card">
      <header class="modal-card-head">
        <p class="modal-card-title">Search</p>
      </header>
      <section class="modal-card-body">
        <div class="field mb-2">
          <div class="control">
            <input class="input" id="search" placeholder="Search this website." type="search" />
          </div>
        </div>
        <div class="search-results">
          <div class="search-results__items"></div>
        </div>
      </section>
    </div>
    <button aria-label="close" class="modal-close is-large"></button>
  </section>
  


  

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <nav class="level">
              
          <div class="level-item has-text-centered">
            <a class="button is-black is-outlined" href="https:&#x2F;&#x2F;animeshchouhan.com&#x2F;posts&#x2F;calculator-percentage&#x2F;">
              <span class="icon mr-2">
                <i class="fas fa-arrow-circle-left"></i>
              </span>
              How Percentage Works in Calculators?
            </a>
          </div>
           
        </nav>
      </div>
    </div>
  </div>
</section>



  



  
  <footer class="footer py-3">
    <div class="content has-text-centered">
      <p style="margin-bottom: 6px;">
        Built with
        <span class="icon-text">
          <span class="icon">
            <i class="fas fa-code"></i>
          </span>
          <!-- <span>code</span> -->
        </span>
        and
        <span class="icon-text">
          <span class="icon">
            <i class="fas fa-heart"></i>
          </span>
          <!-- <span>love</span> -->
        </span>
      </p>
      <!-- <p>
        Powered by
        <span class="icon-text">
          <span class="icon">
            <i class="fas fa-power-off"></i>
          </span>
          <span>zola</span>
        </span>
      </p> -->
      <p>
        <span class="icon-text">
          <span class="icon">
            <i class="far fa-copyright"></i>
          </span>
          <span>2025</span>
        </span>
      </p>
    </div>
  </footer>
  

  <script src="/js/site.js"></script>
  
  
  
  
  <!-- Search scripts -->
  <!-- <script src="/elasticlunr.min.js"></script> -->
  <!-- <script src="/search_index.en.js"></script> -->





  
  
</body>

</html>